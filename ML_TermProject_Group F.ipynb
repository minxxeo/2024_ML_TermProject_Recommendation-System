{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content-Based Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lms26\\AppData\\Local\\Temp\\ipykernel_3416\\4270936755.py:11: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df1 = pd.read_csv(\"C:/Users/lms26/MachineLearning/dataset/reviews_0-250.csv\")\n",
      "C:\\Users\\lms26\\AppData\\Local\\Temp\\ipykernel_3416\\4270936755.py:14: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df4 = pd.read_csv(\"C:/Users/lms26/MachineLearning/dataset/reviews_750-1250.csv\")\n",
      "C:\\Users\\lms26\\AppData\\Local\\Temp\\ipykernel_3416\\4270936755.py:15: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df5 = pd.read_csv(\"C:/Users/lms26/MachineLearning/dataset/reviews_1250-end.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           product_name           brand_name\n",
      "1697                  Eye Revival Brightening Eye Cream             ROSE INC\n",
      "709                          1% Vitamin A Retinol Serum              Farmacy\n",
      "1927  Brightening Eye Cream Mineral SPF 15 with Pept...      Soleil Toujours\n",
      "2345  Peptides + C Energy Eye Concentrate with Vitam...  Youth To The People\n",
      "1910  barrier+ Triple Lipid + Collagen Brightening E...              Skinfix\n",
      "-----------------------------------------------------------------\n",
      "Evaluating recommendations for user_id: 1288462295 with top 10 recommendations\n",
      "Relevant products for user 1288462295: ['P420652', 'P420652', 'P7880', 'P441101', 'P422905', 'P439061', 'P427406', 'P173726', 'P426836', 'P4016', 'P466123', 'P432829', 'P463371', 'P456218', 'P399623', 'P469502', 'P470065', 'P475181', 'P416923', 'P397624', 'P432048', 'P462344', 'P4032', 'P441323', 'P397310', 'P467118', 'P419466', 'P397627', 'P427641', 'P409816', 'P470533', 'P480280', 'P449150', 'P472067', 'P457011', 'P457012', 'P457010', 'P474369', 'P457009']\n",
      "Recommended products for product_id P457011: ['P457010']\n",
      "Recommended products for product_id P457012: ['P457009']\n",
      "Recommended products for product_id P457010: ['P457011']\n",
      "Recommended products for product_id P474369: ['P432240']\n",
      "Recommended products for product_id P457009: ['P457012']\n",
      "Final unique recommended products (Top 10): ['P457009', 'P457011', 'P457012', 'P432240', 'P457010']\n",
      "Evaluation Results - Precision: 0.8000, Recall: 0.1053, F1 Score: 0.1860\n",
      "Precision: 0.8000, Recall: 0.1053, F1 Score: 0.1860\n"
     ]
    }
   ],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "# Load Data\n",
    "# Load review datasets and concatenate\n",
    "df1 = pd.read_csv(\"C:/Users/lms26/MachineLearning/dataset/reviews_0-250.csv\")\n",
    "df2 = pd.read_csv(\"C:/Users/lms26/MachineLearning/dataset/reviews_250-500.csv\")\n",
    "df3 = pd.read_csv(\"C:/Users/lms26/MachineLearning/dataset/reviews_500-750.csv\")\n",
    "df4 = pd.read_csv(\"C:/Users/lms26/MachineLearning/dataset/reviews_750-1250.csv\")\n",
    "df5 = pd.read_csv(\"C:/Users/lms26/MachineLearning/dataset/reviews_1250-end.csv\")\n",
    "df_test = pd.concat([df1,df2,df3,df4,df5], ignore_index=True)\n",
    "\n",
    "# Load product information with error handling for encoding\n",
    "try:\n",
    "    product_info = pd.read_csv('C:/Users/lms26/MachineLearning/dataset/product_info.csv', encoding='utf-8', low_memory=False)\n",
    "except UnicodeDecodeError:\n",
    "    product_info = pd.read_csv('C:/Users/lms26/MachineLearning/dataset/product_info.csv', encoding='ISO-8859-1', low_memory=False)\n",
    "\n",
    "# Filter to keep only relevant products\n",
    "df_test = df_test[df_test['product_id'].isin(product_info['product_id'])]\n",
    "df = product_info[product_info['product_id'].isin(df_test['product_id'])].reset_index(drop=True)\n",
    "\n",
    "# Preprocessing\n",
    "# Drop columns with missing values\n",
    "df = df.dropna(axis=1)\n",
    "\n",
    "# Combine text fields for feature extraction\n",
    "df['combined_features'] = df['product_name'] + ' ' + df['brand_name'] + ' ' + df['primary_category'] + ' ' + df['secondary_category']\n",
    "\n",
    "\n",
    "# TF-IDF Vectorization on combined text features\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df['combined_features'])\n",
    "\n",
    "# Standardize numeric features\n",
    "numeric_features = df[['rating', 'loves_count', 'price_usd']].values\n",
    "scaler = StandardScaler()\n",
    "numeric_features_scaled = scaler.fit_transform(numeric_features)\n",
    "\n",
    "# Model (Cosine Similarity)\n",
    "# Combine TF-IDF and numeric features\n",
    "features_combined = hstack([tfidf_matrix, numeric_features_scaled])\n",
    "\n",
    "# Compute cosine similarity\n",
    "cosine_sim = cosine_similarity(features_combined, features_combined)\n",
    "\n",
    "# Recommendation and Evaluation Functions\n",
    "# Single product recommendation based on cosine similarity\n",
    "def get_recommendations(product_idx, cosine_sim=cosine_sim, k=5):\n",
    "    similarity_scores = list(enumerate(cosine_sim[product_idx]))\n",
    "    sorted_similar_products = sorted(similarity_scores, key=lambda x: x[1], reverse=True)[1:k]\n",
    "    similar_products_idx = [x[0] for x in sorted_similar_products]\n",
    "    similar_products = df.iloc[similar_products_idx]\n",
    "    return similar_products\n",
    "\n",
    "def recommend_products2(product_name, num_recommendations=5):\n",
    "\n",
    "    product_idx = df[df['product_name'] == product_name].index[0]\n",
    "    similarity_scores = list(enumerate(cosine_sim[product_idx]))\n",
    "    \n",
    "    # 유사도 점수를 기준으로 내림차순 정렬 (자기 자신 제외)\n",
    "    sorted_similar_products = sorted(similarity_scores, key=lambda x: x[1], reverse=True)[1:num_recommendations+1]\n",
    "    \n",
    "    # 유사도가 높은 제품의 인덱스 출력\n",
    "    similar_products_idx = [x[0] for x in sorted_similar_products]\n",
    "    similar_products = df.iloc[similar_products_idx]\n",
    "    \n",
    "    return similar_products\n",
    "    \n",
    "recommended_products = recommend_products2(\"Wake Up Honey Eye Cream with Brightening Vitamin C\")\n",
    "\n",
    "print(recommended_products[['product_name', 'brand_name']])\n",
    "print('-----------------------------------------------------------------')\n",
    "\n",
    "# Precision, Recall, and F1 Score calculation functions\n",
    "def precision_at_k(recommended, relevant, k=10):\n",
    "    recommended_top_k = recommended[:k]\n",
    "    relevant_set = set(relevant)\n",
    "    recommended_set = set(recommended_top_k)\n",
    "    intersection = len(recommended_set.intersection(relevant_set))\n",
    "    return intersection / len(recommended_top_k) if len(recommended_top_k) > 0 else 0\n",
    "\n",
    "def recall_at_k(recommended, relevant, k=5):\n",
    "    recommended_top_k = recommended[:k]\n",
    "    relevant_set = set(relevant)\n",
    "    recommended_set = set(recommended_top_k)\n",
    "    intersection = len(recommended_set.intersection(relevant_set))\n",
    "    return intersection / len(relevant_set) if len(relevant_set) > 0 else 0\n",
    "\n",
    "def f1_score_at_k(recommended, relevant, k=5):\n",
    "    precision = precision_at_k(recommended, relevant, k)\n",
    "    recall = recall_at_k(recommended, relevant, k)\n",
    "    return 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "# Get relevant products based on user_id\n",
    "def get_relevant_products(user_id, df_test):\n",
    "    user_reviews = df_test[df_test['author_id'] == user_id]\n",
    "    return user_reviews['product_id'].tolist() if not user_reviews.empty else []\n",
    "\n",
    "# Evaluate recommendations for a specific user_id\n",
    "def evaluate_recommendations(user_id, k=10):\n",
    "    print(f\"Evaluating recommendations for user_id: {user_id} with top {k} recommendations\")\n",
    "    \n",
    "    # Step 1: Get relevant products for the given user\n",
    "    relevant_products = get_relevant_products(user_id, df_test)\n",
    "    print(f\"Relevant products for user {user_id}: {relevant_products}\")\n",
    "\n",
    "    if not relevant_products:\n",
    "        print(f\"No relevant products found for user {user_id}. Exiting evaluation.\")\n",
    "        return 0, 0, 0\n",
    "\n",
    "    # Step 2: Generate recommendations based on relevant products\n",
    "    all_recommended = []\n",
    "    for product_id in relevant_products[-5:]:\n",
    "        if product_id in df['product_id'].values:\n",
    "            product_idx = df[df['product_id'] == product_id].index[0]\n",
    "            recommended_products = get_recommendations(product_idx=product_idx, k=int(k/5))['product_id'].tolist()\n",
    "            print(f\"Recommended products for product_id {product_id}: {recommended_products}\")\n",
    "            all_recommended.extend(recommended_products)\n",
    "        else:\n",
    "            print(f\"Product ID {product_id} not found in product dataset.\")\n",
    "\n",
    "    # Step 3: Process final recommendations\n",
    "    all_recommended = list(set(all_recommended))[:k]\n",
    "    print(f\"Final unique recommended products (Top {k}): {all_recommended}\")\n",
    "\n",
    "    # Step 4: Calculate evaluation metrics\n",
    "    precision = precision_at_k(all_recommended, relevant_products, k)\n",
    "    recall = recall_at_k(all_recommended, relevant_products, k)\n",
    "    f1 = f1_score_at_k(all_recommended, relevant_products, k)\n",
    "    \n",
    "    print(f\"Evaluation Results - Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
    "    return precision, recall, f1\n",
    "\n",
    "# Test the function with a specific user_id\n",
    "user_id = 1288462295  # Example user_id\n",
    "precision, recall, f1 = evaluate_recommendations(user_id, k=10)\n",
    "print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User-based Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lms26\\AppData\\Local\\Temp\\ipykernel_3416\\1310224463.py:18: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_review_1 = pd.read_csv('C:/Users/lms26/MachineLearning/dataset/reviews_0-250.csv', dtype={'product_id': str}, encoding='ISO-8859-1')\n",
      "C:\\Users\\lms26\\AppData\\Local\\Temp\\ipykernel_3416\\1310224463.py:21: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_review_4 = pd.read_csv('C:/Users/lms26/MachineLearning/dataset/reviews_750-1250.csv', dtype={'product_id': str}, encoding='ISO-8859-1')\n",
      "C:\\Users\\lms26\\AppData\\Local\\Temp\\ipykernel_3416\\1310224463.py:22: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_review_5 = pd.read_csv('C:/Users/lms26/MachineLearning/dataset/reviews_1250-end.csv', dtype={'product_id': str}, encoding='ISO-8859-1')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Loading and Filtering Complete\n",
      "Train-Test Split Complete\n",
      "User Similarity Calculation Complete\n",
      "\n",
      "Recommended Products for user 11392228549:\n",
      "\n",
      "[ Brand ]            [ Product Name ]                                            \n",
      "Augustinus Bader     The Cream Cleansing Gel with TFC8 Gentle Cleanser           \n",
      "Sunday Riley         Good Genes All-In-One AHA Lactic Acid Treatment             \n",
      "Summer Fridays       Jet Lag Mask                                                \n",
      "Dermalogica          Mini Daily Microfoliant Exfoliator                          \n",
      "Summer Fridays       Mini Jet Lag Mask                                           \n",
      "\n",
      "Evaluating model performance (RMSE)...\n",
      "RMSE of the recommendation system: 0.9233250184502947\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from random import sample\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import os\n",
    "\n",
    "# Step 1: Load and Preprocess Data\n",
    "# --------------------------------\n",
    "\n",
    "# Load datasets\n",
    "# Load datasets with specific encoding\n",
    "df_product = pd.read_csv('C:/Users/lms26/MachineLearning/dataset/product_info.csv', dtype={'product_id': str}, encoding='ISO-8859-1')\n",
    "df_review_1 = pd.read_csv('C:/Users/lms26/MachineLearning/dataset/reviews_0-250.csv', dtype={'product_id': str}, encoding='ISO-8859-1')\n",
    "df_review_2 = pd.read_csv('C:/Users/lms26/MachineLearning/dataset/reviews_250-500.csv', dtype={'product_id': str}, encoding='ISO-8859-1')\n",
    "df_review_3 = pd.read_csv('C:/Users/lms26/MachineLearning/dataset/reviews_500-750.csv', dtype={'product_id': str}, encoding='ISO-8859-1')\n",
    "df_review_4 = pd.read_csv('C:/Users/lms26/MachineLearning/dataset/reviews_750-1250.csv', dtype={'product_id': str}, encoding='ISO-8859-1')\n",
    "df_review_5 = pd.read_csv('C:/Users/lms26/MachineLearning/dataset/reviews_1250-end.csv', dtype={'product_id': str}, encoding='ISO-8859-1')\n",
    "\n",
    "\n",
    "# Combine reviews and keep necessary columns\n",
    "df_reviews_combined = pd.concat([df_review_1, df_review_2, df_review_3, df_review_4, df_review_5], ignore_index=True)\n",
    "df_reviews_filtered = df_reviews_combined[['author_id', 'product_id', 'rating']].dropna()\n",
    "\n",
    "# Filter out users and products with fewer than n number.\n",
    "user_counts = df_reviews_filtered['author_id'].value_counts()\n",
    "product_counts = df_reviews_filtered['product_id'].value_counts()\n",
    "active_users = user_counts[user_counts >= 5].index # Minimum 5 reviews for users\n",
    "popular_products = product_counts[product_counts >= 10].index # Minimum 10 reviews for products\n",
    "\n",
    "df_reviews_filtered = df_reviews_filtered[(df_reviews_filtered['author_id'].isin(active_users)) & \n",
    "                                          (df_reviews_filtered['product_id'].isin(popular_products))]\n",
    "\n",
    "print(\"Data Loading and Filtering Complete\")\n",
    "\n",
    "# Step 2: Create User-Item Matrix and Normalize Ratings\n",
    "# ------------------------------------------------------\n",
    "\n",
    "# Create user-item matrix\n",
    "user_item_matrix = df_reviews_filtered.pivot_table(index='author_id', columns='product_id', values='rating')\n",
    "\n",
    "# Center ratings by subtracting the user's mean rating from each rating\n",
    "user_means = user_item_matrix.mean(axis=1)  # Calculate mean rating for each user\n",
    "user_item_matrix = user_item_matrix.sub(user_means, axis=0).fillna(0)  # Center ratings and fill NaN with 0\n",
    "\n",
    "# Convert to sparse matrix for memory efficiency\n",
    "user_item_sparse = csr_matrix(user_item_matrix)\n",
    "\n",
    "# Step 3: Train-Test Split\n",
    "# ------------------------\n",
    "\n",
    "# Split data into training and testing sets\n",
    "train_data, test_data = train_test_split(df_reviews_filtered, test_size=0.2, random_state=42)\n",
    "train_user_item_matrix = train_data.pivot_table(index='author_id', columns='product_id', values='rating')\n",
    "\n",
    "# Center training data by subtracting the user's mean rating\n",
    "train_user_means = train_user_item_matrix.mean(axis=1)\n",
    "train_user_item_matrix = train_user_item_matrix.sub(train_user_means, axis=0).fillna(0)\n",
    "\n",
    "# Convert to sparse matrix\n",
    "train_user_item_sparse = csr_matrix(train_user_item_matrix)\n",
    "\n",
    "print(\"Train-Test Split Complete\")\n",
    "\n",
    "# Step 4: Calculate User Similarity\n",
    "# ---------------------------------\n",
    "\n",
    "# Calculate user similarity matrix using cosine similarity\n",
    "user_similarity = cosine_similarity(train_user_item_sparse)\n",
    "user_similarity_df = pd.DataFrame(user_similarity, index=train_user_item_matrix.index, columns=train_user_item_matrix.index)\n",
    "print(\"User Similarity Calculation Complete\")\n",
    "\n",
    "# Step 5: Implement Recommendation System\n",
    "# ---------------------------------------\n",
    "\n",
    "def user_based_recommendations(user_id, num_recommendations=5):\n",
    "    # Ensure the user exists in the training data\n",
    "    if user_id not in user_similarity_df.index:\n",
    "        return pd.DataFrame(columns=['product_id', 'score'])\n",
    "\n",
    "    # Find similar users\n",
    "    similar_users = user_similarity_df[user_id].sort_values(ascending=False).iloc[1:num_recommendations+1].index\n",
    "    \n",
    "    # Get ratings of similar users\n",
    "    similar_user_ratings = train_user_item_matrix.loc[similar_users]\n",
    "    user_ratings = train_user_item_matrix.loc[user_id]\n",
    "    \n",
    "    # Recommend products that the user has not rated yet\n",
    "    recommendations = similar_user_ratings.mean().loc[user_ratings[user_ratings == 0].index]\n",
    "    recommendations = recommendations.sort_values(ascending=False).head(num_recommendations)\n",
    "\n",
    "    # Map product_id to product name and brand\n",
    "    recommendation_df = pd.DataFrame(recommendations).reset_index()\n",
    "    recommendation_df.columns = ['product_id', 'score']\n",
    "    recommendation_df = recommendation_df.merge(df_product[['product_id', 'product_name', 'brand_name']], on='product_id', how='left')\n",
    "    \n",
    "    return recommendation_df[['product_id', 'product_name', 'brand_name', 'score']]\n",
    "\n",
    "\n",
    "\n",
    "# Step 6: Evaluate Recommendation System with RMSE\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "def evaluate_recommendation_system(batch_size=100, sample_size=500):\n",
    "    actual_ratings = []\n",
    "    predicted_ratings = []\n",
    "\n",
    "    test_sample = test_data.sample(n=sample_size, random_state=42)\n",
    "\n",
    "    for i in range(0, len(test_sample), batch_size):\n",
    "        batch = test_sample.iloc[i:i+batch_size]\n",
    "\n",
    "        for _, row in batch.iterrows():\n",
    "            user_id = row['author_id']\n",
    "            product_id = row['product_id']\n",
    "            actual_rating = row['rating']\n",
    "\n",
    "            if user_id in user_similarity_df.index and product_id in train_user_item_matrix.columns:\n",
    "                user_recommendations = user_based_recommendations(user_id)\n",
    "                if product_id in user_recommendations['product_id'].values:\n",
    "                    predicted_rating = user_recommendations[user_recommendations['product_id'] == product_id]['score'].values[0] + train_user_means[user_id]\n",
    "                else:\n",
    "                    predicted_rating = train_user_means[user_id]\n",
    "            else:\n",
    "                predicted_rating = train_user_item_matrix.values.mean()\n",
    "            \n",
    "            actual_ratings.append(actual_rating)\n",
    "            predicted_ratings.append(predicted_rating)\n",
    "    \n",
    "    rmse = sqrt(mean_squared_error(actual_ratings, predicted_ratings))\n",
    "    return rmse\n",
    "\n",
    "# Example Usage with Formatted Output\n",
    "# -----------------------------------\n",
    "\n",
    "user_id = input(\"Enter the user ID for product recommendations: \")\n",
    "\n",
    "if user_id in user_similarity_df.index:\n",
    "    recommendations = user_based_recommendations(user_id, num_recommendations=5)\n",
    "    print(f\"\\nRecommended Products for user {user_id}:\\n\")\n",
    "    print(f\"{'[ Brand ]':<20} {'[ Product Name ]':<60}\")\n",
    "    for _, row in recommendations.iterrows():\n",
    "        print(f\"{row['brand_name']:<20} {row['product_name']:<60}\")\n",
    "else:\n",
    "    print(f\"User ID {user_id} not found in the dataset.\")\n",
    "\n",
    "# Evaluate model performance with RMSE\n",
    "print(\"\\nEvaluating model performance (RMSE)...\")\n",
    "rmse_score = evaluate_recommendation_system()\n",
    "print(f\"RMSE of the recommendation system: {rmse_score}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybrid Filtering Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lms26\\AppData\\Local\\Temp\\ipykernel_3416\\1023591610.py:18: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_review_1 = pd.read_csv('C:/Users/lms26/MachineLearning/dataset/reviews_0-250.csv', dtype={'product_id': str}, encoding='ISO-8859-1')\n",
      "C:\\Users\\lms26\\AppData\\Local\\Temp\\ipykernel_3416\\1023591610.py:21: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_review_4 = pd.read_csv('C:/Users/lms26/MachineLearning/dataset/reviews_750-1250.csv', dtype={'product_id': str}, encoding='ISO-8859-1')\n",
      "C:\\Users\\lms26\\AppData\\Local\\Temp\\ipykernel_3416\\1023591610.py:22: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_review_5 = pd.read_csv('C:/Users/lms26/MachineLearning/dataset/reviews_1250-end.csv', dtype={'product_id': str}, encoding='ISO-8859-1')\n",
      "C:\\Users\\lms26\\AppData\\Local\\Temp\\ipykernel_3416\\1023591610.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_reviews_filtered['product_id'] = df_reviews_filtered['product_id'].astype(str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Recommended Products for user 1979739038 :\n",
      "\n",
      "     [ Brand ]                             [ Product Name ]\n",
      "      CLINIQUE           Moisture Surge Overnight Face Mask\n",
      "Drunk Elephant      T.L.C. Sukari Babyfacial AHA + BHA Mask\n",
      "         fresh     Sugar Recovery Lip Mask Advanced Therapy\n",
      "   Glow Recipe   Watermelon Glow PHA + BHA Pore-Tight Toner\n",
      "     Herbivore Blue Tansy BHA and Enzyme Pore Refining Mask\n",
      "\n",
      "RMSE of Recommendation System: 0.7983647394160953\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from math import sqrt\n",
    "\n",
    "# Step 1: Load and Preprocess Data\n",
    "# --------------------------------\n",
    "\n",
    "# Load datasets\n",
    "# Load datasets with specific encoding\n",
    "df_product = pd.read_csv('C:/Users/lms26/MachineLearning/dataset/product_info.csv', dtype={'product_id': str}, encoding='ISO-8859-1')\n",
    "df_review_1 = pd.read_csv('C:/Users/lms26/MachineLearning/dataset/reviews_0-250.csv', dtype={'product_id': str}, encoding='ISO-8859-1')\n",
    "df_review_2 = pd.read_csv('C:/Users/lms26/MachineLearning/dataset/reviews_250-500.csv', dtype={'product_id': str}, encoding='ISO-8859-1')\n",
    "df_review_3 = pd.read_csv('C:/Users/lms26/MachineLearning/dataset/reviews_500-750.csv', dtype={'product_id': str}, encoding='ISO-8859-1')\n",
    "df_review_4 = pd.read_csv('C:/Users/lms26/MachineLearning/dataset/reviews_750-1250.csv', dtype={'product_id': str}, encoding='ISO-8859-1')\n",
    "df_review_5 = pd.read_csv('C:/Users/lms26/MachineLearning/dataset/reviews_1250-end.csv', dtype={'product_id': str}, encoding='ISO-8859-1')\n",
    "\n",
    "\n",
    "# Combine reviews and keep necessary columns\n",
    "df_reviews_combined = pd.concat([df_review_1, df_review_2, df_review_3, df_review_4, df_review_5], ignore_index=True)\n",
    "df_reviews_filtered = df_reviews_combined[['author_id', 'rating', 'product_id']]\n",
    "df_product = df_product[['product_id', 'product_name', 'brand_name', 'ingredients', 'primary_category', 'secondary_category', 'tertiary_category']]\n",
    "\n",
    "# Ensure product_id is the same type in both dataframes\n",
    "df_product['product_id'] = df_product['product_id'].astype(str)\n",
    "df_reviews_filtered['product_id'] = df_reviews_filtered['product_id'].astype(str)\n",
    "\n",
    "# Filter out products with 'Mini Size' in any category\n",
    "df_product = df_product[\n",
    "    ~(df_product['primary_category'] == 'Mini Size') &\n",
    "    ~(df_product['secondary_category'] == 'Mini Size') &\n",
    "    ~(df_product['tertiary_category'] == 'Mini Size')\n",
    "]\n",
    "\n",
    "# Filter out users and products with fewer than n number of reviews\n",
    "user_counts = df_reviews_filtered['author_id'].value_counts()\n",
    "product_counts = df_reviews_filtered['product_id'].value_counts()\n",
    "active_users = user_counts[user_counts >= 10].index  # Minimum 10 reviews for users\n",
    "popular_products = product_counts[product_counts >= 10].index  # Minimum 10 reviews for products\n",
    "df_reviews_filtered = df_reviews_filtered[df_reviews_filtered['author_id'].isin(active_users) & df_reviews_filtered['product_id'].isin(popular_products)]\n",
    "\n",
    "# Merge review and product data\n",
    "user_product_review = pd.merge(df_reviews_filtered, df_product, on='product_id')\n",
    "\n",
    "# User-Centric Normalization\n",
    "user_mean_rating = user_product_review.groupby('author_id')['rating'].mean()\n",
    "user_product_review = user_product_review.join(user_mean_rating, on='author_id', rsuffix='_mean')\n",
    "user_product_review['rating'] = user_product_review['rating'] - user_product_review['rating_mean']\n",
    "\n",
    "# Step 2: Encoding and Creating User-Item Matrix\n",
    "# ----------------------------------------------\n",
    "\n",
    "# Encode user and product IDs to numerical values\n",
    "encoder_user = LabelEncoder()\n",
    "encoder_product = LabelEncoder()\n",
    "user_product_review['original_author_id'] = user_product_review['author_id']  # Save original IDs for reference\n",
    "user_product_review['author_id'] = encoder_user.fit_transform(user_product_review['author_id'].astype(str))\n",
    "user_product_review['product_id'] = encoder_product.fit_transform(user_product_review['product_id'].astype(str))\n",
    "\n",
    "# Create user-item rating matrix (CSR format for memory efficiency)\n",
    "num_users = user_product_review['author_id'].nunique()\n",
    "num_products = user_product_review['product_id'].nunique()\n",
    "user_item_matrix = csr_matrix((user_product_review['rating'],\n",
    "                               (user_product_review['author_id'], user_product_review['product_id'])),\n",
    "                               shape=(num_users, num_products))\n",
    "\n",
    "# Step 3: Train-Test Split\n",
    "# ------------------------\n",
    "\n",
    "# Split data into training and testing sets\n",
    "train_data, test_data = train_test_split(user_product_review, test_size=0.2, random_state=42)\n",
    "train_user_item_matrix = csr_matrix((train_data['rating'],\n",
    "                                     (train_data['author_id'], train_data['product_id'])),\n",
    "                                     shape=(num_users, num_products))\n",
    "test_user_item_matrix = csr_matrix((test_data['rating'],\n",
    "                                    (test_data['author_id'], test_data['product_id'])),\n",
    "                                    shape=(num_users, num_products))\n",
    "\n",
    "# Step 4: User-basd Collaborative Filtering (KNN model for user similarity)\n",
    "# -------------------------------------------------------------------------\n",
    "\n",
    "k = 10\n",
    "model_knn = NearestNeighbors(metric='cosine', algorithm='brute', n_neighbors=k, n_jobs=-1)\n",
    "model_knn.fit(train_user_item_matrix)\n",
    "\n",
    "# Step 5: Content-Based Filtering (TD-IDF vectorization on product ingredients)\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df_product['ingredients'].astype(str))\n",
    "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "# Step 6: Generate Recommendations\n",
    "# --------------------------------\n",
    "\n",
    "# Get user input for generating recommendations\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "original_user_id = str(input(\"Enter the user ID for product recommendations: \")) # valid id: 11392228549\n",
    "if original_user_id not in user_product_review['original_author_id'].astype(str).values:\n",
    "    raise ValueError(\"The user ID you entered is invalid. Please try again.\")\n",
    "\n",
    "user_idx = encoder_user.transform([original_user_id])[0]\n",
    "\n",
    "# Find k similar users, excluding the user themselves\n",
    "if user_idx < num_users:\n",
    "    distances, indices = model_knn.kneighbors(train_user_item_matrix[user_idx], n_neighbors=k + 1)\n",
    "    similar_users = indices.flatten()[1:]  # Exclude the user themselves\n",
    "\n",
    "    # Collaborative Filtering scores for recommendation\n",
    "    product_scores_cf = np.zeros(num_products)\n",
    "    for similar_user in similar_users[:k]:\n",
    "        product_scores_cf += train_user_item_matrix[similar_user].toarray().flatten()\n",
    "\n",
    "    # Combine Collaborative Filtering and Content-Based scores\n",
    "    hybrid_scores = product_scores_cf\n",
    "    for product_id in range(num_products):\n",
    "        if product_id < cosine_sim.shape[1]:\n",
    "            hybrid_scores[product_id] += cosine_sim[user_idx % cosine_sim.shape[0], product_id]\n",
    "\n",
    "    # Recommend top products\n",
    "    recommended_products = np.argsort(hybrid_scores)[-10:][::-1]\n",
    "    recommended_product_info = df_product[df_product['product_id'].isin(encoder_product.inverse_transform(recommended_products))]\n",
    "\n",
    "    # Display top 5 unique recommended products\n",
    "    pd.set_option('display.width', 1000)\n",
    "    pd.set_option('display.max_colwidth', None)\n",
    "    recommended_product_info = recommended_product_info[['brand_name', 'product_name']].drop_duplicates().reset_index(drop=True).head(5)\n",
    "    recommended_product_info = recommended_product_info.rename(columns={'brand_name': '[ Brand ]', 'product_name': '[ Product Name ]'})\n",
    "    print(f\"\\nRecommended Products for user {original_user_id} :\\n\")\n",
    "    print(recommended_product_info.to_string(index=False))\n",
    "\n",
    "else:\n",
    "    print(f\"User ID {user_idx} is invalid. Please try again.\")\n",
    "\n",
    "# Step 7: Evaluation - RMSE\n",
    "# -------------------------\n",
    "\n",
    "y_true = test_data['rating'] # actual ratings from test set\n",
    "\n",
    "y_pred = [] # predicted ratings for test set\n",
    "for user_id, product_id in zip(test_data['author_id'], test_data['product_id']):\n",
    "    if train_user_item_matrix[user_id, product_id] != 0:\n",
    "        y_pred.append(train_user_item_matrix[user_id, product_id])\n",
    "    else:\n",
    "        y_pred.append(np.mean(train_user_item_matrix[user_id].data))  # Use user's mean rating if specific prediction is unavailable\n",
    "\n",
    "# Remove NaN values from predictions and true values\n",
    "y_pred = np.array(y_pred)\n",
    "valid_idx = ~np.isnan(y_pred)\n",
    "y_true = y_true[valid_idx]\n",
    "y_pred = y_pred[valid_idx]\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE) for evaluation\n",
    "rmse = sqrt(mean_squared_error(y_true, y_pred))\n",
    "print(f\"\\nRMSE of Recommendation System: {rmse}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
